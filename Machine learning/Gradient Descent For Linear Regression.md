#Machinelearning
**Overview:** Batch Gradient Descent is an optimization algorithm used to minimize the cost function in machine learning models. It involves computing the gradient of the cost function with respect to the parameters using the entire training dataset before updating the parameters.

![[The Derivative of w and b.png]]